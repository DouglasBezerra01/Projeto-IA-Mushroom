{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHQTp5JcEyX",
        "outputId": "098e3550-e86c-4c55-8243-323c1b489b55"
      },
      "source": [
        "import os\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Suprime avisos para uma saída mais limpa\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuração\n",
        "DATASET_FILENAME = 'agaricus-lepiota.data'\n",
        "PROCESSED_FILENAME = 'mushroom_processed_final.csv'\n",
        "\n",
        "COLUMNS = [\n",
        "    'class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n",
        "    'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape',\n",
        "    'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring',\n",
        "    'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type',\n",
        "    'veil-color', 'ring-number', 'ring-type', 'spore-print-color',\n",
        "    'population', 'habitat'\n",
        "]\n",
        "\n",
        "def load_and_preprocess_data():\n",
        "    \"\"\"\n",
        "    Carrega o dataset, trata valores ausentes descartando linhas (abordagem conservadora),\n",
        "    e aplica One-Hot Encoding.\n",
        "\n",
        "    Retorna:\n",
        "        X (pd.DataFrame): Matriz de características.\n",
        "        y (pd.Series): Vetor alvo.\n",
        "    \"\"\"\n",
        "    # 1. Carregamento\n",
        "    if not os.path.exists(DATASET_FILENAME):\n",
        "        print(f\"O arquivo {DATASET_FILENAME} não foi encontrado. Certifique-se de que está no diretório correto.\")\n",
        "        return None, None\n",
        "\n",
        "    df = pd.read_csv(DATASET_FILENAME, header=None, names=COLUMNS, na_values='?')\n",
        "    initial_shape = df.shape\n",
        "    print(f\"Formato original do dataset: {initial_shape}\")\n",
        "\n",
        "    # 2. Tratamento de Valores Ausentes (Abordagem Conservadora)\n",
        "    # Descartando linhas com valores ausentes para manter a integridade dos dados\n",
        "    df_clean = df.dropna().reset_index(drop=True)\n",
        "    dropped_rows = initial_shape[0] - df_clean.shape[0]\n",
        "    print(f\"Linhas descartadas devido a valores ausentes: {dropped_rows} ({(dropped_rows/initial_shape[0]):.2%})\")\n",
        "\n",
        "    # 3. Codificação\n",
        "    X = df_clean.drop('class', axis=1)\n",
        "    y = df_clean['class']\n",
        "\n",
        "    # Codifica o Alvo (0=comestível, 1=venenoso)\n",
        "    le = LabelEncoder()\n",
        "    y_encoded = le.fit_transform(y)\n",
        "\n",
        "    # Codifica as Características (One-Hot Encoding)\n",
        "    X_encoded = pd.get_dummies(X)\n",
        "\n",
        "    print(f\"Formato do dataset processado: {X_encoded.shape}\")\n",
        "\n",
        "    # Salva para registro\n",
        "    df_final = pd.concat([pd.DataFrame(y_encoded, columns=['target']), X_encoded], axis=1)\n",
        "    df_final.to_csv(PROCESSED_FILENAME, index=False)\n",
        "\n",
        "    return X_encoded, y_encoded\n",
        "\n",
        "def get_models_configuration():\n",
        "    \"\"\"Define os modelos e grades de hiperparâmetros.\"\"\"\n",
        "    return [\n",
        "        {\n",
        "            'name': 'Árvore de Decisão',\n",
        "            'model': DecisionTreeClassifier(random_state=42),\n",
        "            'params': {\n",
        "                'criterion': ['gini', 'entropy'],\n",
        "                'max_depth': [None, 10, 5],\n",
        "                'min_samples_split': [2, 5]\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            'name': 'KNN',\n",
        "            'model': KNeighborsClassifier(),\n",
        "            'params': {\n",
        "                'n_neighbors': [3, 5, 7],\n",
        "                'weights': ['uniform', 'distance'],\n",
        "                'metric': ['euclidean', 'manhattan']\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            'name': 'Naive Bayes',\n",
        "            'model': GaussianNB(),\n",
        "            'params': {\n",
        "                'var_smoothing': [1e-9, 1e-8, 1e-7]\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            'name': 'Regressão Logística',\n",
        "            'model': LogisticRegression(max_iter=1000, random_state=42),\n",
        "            'params': {\n",
        "                'C': [0.1, 1, 10],\n",
        "                'solver': ['liblinear', 'lbfgs']\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            'name': 'Rede Neural MLP',\n",
        "            'model': MLPClassifier(max_iter=500, random_state=42),\n",
        "            'params': {\n",
        "                'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
        "                'activation': ['relu', 'tanh'],\n",
        "                'alpha': [0.0001, 0.001]\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "\n",
        "def _run_single_fold_evaluation(model_config, X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Função auxiliar para executar GridSearchCV e avaliar um modelo para uma única dobra.\n",
        "    Retorna best_params, acurácia, precisão, recall, f1.\n",
        "    \"\"\"\n",
        "    grid_search = GridSearchCV(\n",
        "        model_config['model'],\n",
        "        model_config['params'],\n",
        "        scoring='accuracy',\n",
        "        cv=3,\n",
        "        n_jobs=-1,\n",
        "        refit=True\n",
        "    )\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_params = str(grid_search.best_params_)\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    return best_params, acc, prec, rec, f1\n",
        "\n",
        "def run_nested_cross_validation(X, y, n_splits=10):\n",
        "    \"\"\"\n",
        "    Realiza Validação Cruzada Aninhada para prevenir vazamento de dados durante o ajuste de hiperparâmetros.\n",
        "    \"\"\"\n",
        "    cv_outer = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    models_config = get_models_configuration()\n",
        "    results_summary = []\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"{'INICIANDO VALIDAÇÃO CRUZADA ANINHADA (10-FOLD)':^80}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    for config in models_config:\n",
        "        model_name = config['name']\n",
        "        print(f\"\\nProcessando Modelo: {model_name}...\")\n",
        "\n",
        "        fold_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
        "        best_params_tracker = []\n",
        "\n",
        "        # Loop Externo: Avaliação\n",
        "        for fold_idx, (train_ix, test_ix) in enumerate(cv_outer.split(X, y)):\n",
        "            X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
        "            y_train, y_test = y[train_ix], y[test_ix]\n",
        "\n",
        "            # Executa o GridSearchCV e avalia o modelo para esta dobra\n",
        "            best_params, acc, prec, rec, f1 = _run_single_fold_evaluation(\n",
        "                config, X_train, y_train, X_test, y_test\n",
        "            )\n",
        "\n",
        "            # Armazena os melhores parâmetros para esta dobra\n",
        "            best_params_tracker.append(best_params)\n",
        "\n",
        "            # Adiciona as métricas para esta dobra\n",
        "            fold_metrics['accuracy'].append(acc)\n",
        "            fold_metrics['precision'].append(prec)\n",
        "            fold_metrics['recall'].append(rec)\n",
        "            fold_metrics['f1'].append(f1)\n",
        "\n",
        "        # Agregando resultados\n",
        "        mean_acc = np.mean(fold_metrics['accuracy'])\n",
        "        std_acc = np.std(fold_metrics['accuracy'])\n",
        "        mean_f1 = np.mean(fold_metrics['f1'])\n",
        "        std_f1 = np.std(fold_metrics['f1'])\n",
        "\n",
        "        # Encontra os parâmetros mais comuns em todas as dobras\n",
        "        from collections import Counter\n",
        "        most_common_params = Counter(best_params_tracker).most_common(1)[0][0]\n",
        "\n",
        "        print(f\"   Acurácia: {mean_acc:.4f} (+/- {std_acc:.4f})\")\n",
        "        print(f\"   Pontuação F1: {mean_f1:.4f}\")\n",
        "\n",
        "        results_summary.append({\n",
        "            'Algorithm': model_name,\n",
        "            'Accuracy': f\"{mean_acc:.4f} ± {std_acc:.4f}\",\n",
        "            'Precision': f\"{np.mean(fold_metrics['precision']):.4f} ± {np.std(fold_metrics['precision']):.4f}\",\n",
        "            'Recall': f\"{np.mean(fold_metrics['recall']):.4f} ± {np.std(fold_metrics['recall']):.4f}\",\n",
        "            'F1-Score': f\"{mean_f1:.4f} ± {std_f1:.4f}\",\n",
        "            'Best Params (Mode)': most_common_params\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results_summary)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Pré-processamento\n",
        "    X, y = load_and_preprocess_data()\n",
        "\n",
        "    if X is not None:\n",
        "        # 2. Execução\n",
        "        df_results = run_nested_cross_validation(X, y)\n",
        "\n",
        "        # 3. Relatório Final\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(f\"{'RELATÓRIO FINAL DE DESEMPENHO':^80}\")\n",
        "        print(\"=\"*80)\n",
        "        print(df_results.drop('Best Params (Mode)', axis=1).to_markdown(index=False))\n",
        "\n",
        "        # Salva resultados detalhados\n",
        "        df_results.to_csv('final_model_evaluation.csv', index=False)\n",
        "        print(\"\\nResultados detalhados salvos em 'final_model_evaluation.csv'.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato original do dataset: (8124, 23)\n",
            "Linhas descartadas devido a valores ausentes: 2480 (30.53%)\n",
            "Formato do dataset processado: (5644, 98)\n",
            "\n",
            "================================================================================\n",
            "                 INICIANDO VALIDAÇÃO CRUZADA ANINHADA (10-FOLD)                 \n",
            "================================================================================\n",
            "\n",
            "Processando Modelo: Árvore de Decisão...\n",
            "   Acurácia: 1.0000 (+/- 0.0000)\n",
            "   Pontuação F1: 1.0000\n",
            "\n",
            "Processando Modelo: KNN...\n",
            "   Acurácia: 1.0000 (+/- 0.0000)\n",
            "   Pontuação F1: 1.0000\n",
            "\n",
            "Processando Modelo: Naive Bayes...\n",
            "   Acurácia: 0.9981 (+/- 0.0017)\n",
            "   Pontuação F1: 0.9975\n",
            "\n",
            "Processando Modelo: Regressão Logística...\n",
            "   Acurácia: 1.0000 (+/- 0.0000)\n",
            "   Pontuação F1: 1.0000\n",
            "\n",
            "Processando Modelo: Rede Neural MLP...\n",
            "   Acurácia: 1.0000 (+/- 0.0000)\n",
            "   Pontuação F1: 1.0000\n",
            "\n",
            "================================================================================\n",
            "                         RELATÓRIO FINAL DE DESEMPENHO                          \n",
            "================================================================================\n",
            "| Algorithm           | Accuracy        | Precision       | Recall          | F1-Score        |\n",
            "|:--------------------|:----------------|:----------------|:----------------|:----------------|\n",
            "| Árvore de Decisão   | 1.0000 ± 0.0000 | 1.0000 ± 0.0000 | 1.0000 ± 0.0000 | 1.0000 ± 0.0000 |\n",
            "| KNN                 | 1.0000 ± 0.0000 | 1.0000 ± 0.0000 | 1.0000 ± 0.0000 | 1.0000 ± 0.0000 |\n",
            "| Naive Bayes         | 0.9981 ± 0.0017 | 0.9949 ± 0.0043 | 1.0000 ± 0.0000 | 0.9975 ± 0.0022 |\n",
            "| Regressão Logística | 1.0000 ± 0.0000 | 1.0000 ± 0.0000 | 1.0000 ± 0.0000 | 1.0000 ± 0.0000 |\n",
            "| Rede Neural MLP     | 1.0000 ± 0.0000 | 1.0000 ± 0.0000 | 1.0000 ± 0.0000 | 1.0000 ± 0.0000 |\n",
            "\n",
            "Resultados detalhados salvos em 'final_model_evaluation.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Carregar o arquivo de resultados já gerado\n",
        "try:\n",
        "    df = pd.read_csv('final_model_evaluation.csv')\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"TABELA 1: MELHORES HIPERPARÂMETROS (Copie as linhas abaixo para o Word)\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"| {'Algorithm':<20} | {'Melhores Hiperparâmetros (Moda)':<50} |\")\n",
        "    print(f\"|{'-'*22}|{'-'*52}|\")\n",
        "\n",
        "    # 2. Iterar e formatar para ficar bonito no artigo\n",
        "    for index, row in df.iterrows():\n",
        "        # Pega a coluna 'Best Params (Mode)' ou 'Melhores Params (Moda)' dependendo da versão que rodou\n",
        "        params = row.get('Best Params (Mode)', row.get('Melhores Params (Moda)', 'Coluna não encontrada'))\n",
        "\n",
        "        # Limpeza visual para o artigo (tira chaves e aspas)\n",
        "        params_limpo = str(params).replace(\"{\", \"\").replace(\"}\", \"\").replace(\"'\", \"\")\n",
        "\n",
        "        print(f\"| {row['Algorithm']:<20} | {params_limpo:<50} |\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"ERRO: O arquivo 'final_model_evaluation.csv' não foi encontrado.\")\n",
        "    print(\"Verifique se você rodou o código de treinamento anterior completamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWCd7CXSW5sG",
        "outputId": "b42ac4b8-332b-4bef-9171-dc29960fcf83"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "TABELA 1: MELHORES HIPERPARÂMETROS (Copie as linhas abaixo para o Word)\n",
            "================================================================================\n",
            "| Algorithm            | Melhores Hiperparâmetros (Moda)                    |\n",
            "|----------------------|----------------------------------------------------|\n",
            "| Árvore de Decisão    | criterion: gini, max_depth: None, min_samples_split: 2 |\n",
            "| KNN                  | metric: manhattan, n_neighbors: 7, weights: distance |\n",
            "| Naive Bayes          | var_smoothing: 1e-09                               |\n",
            "| Regressão Logística  | C: 10, solver: lbfgs                               |\n",
            "| Rede Neural MLP      | activation: tanh, alpha: 0.0001, hidden_layer_sizes: (100,) |\n"
          ]
        }
      ]
    }
  ]
}